# -*- coding: utf-8 -*-
"""Copy of Barrier_crossing_oliver_zosia.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Kc8Tssn5FO9iDnZcV2AmbmEc0IxmWyuF

What I learned with Megan today: she explained the main parts of the code. The first part is the brownian particle simulation which theoretically is the same as the code from the JAX M.D. cookbook in generic simulation concepts. The important idea here is that they program the potential energy by hand using this energy well thing and all we're doing is programming the movement of a single particle in 1D space (???). And a harmonic trap/spring that seems to be what moves the actual particle.

The end goal that megan has is that she wants to discover the free energy landscape of a different particle purely from auto diff/convergence of the error. We are tuning the chebyshev coefficients in order to reduce the work used (which right now is a proxy for the error of the ensemble average of e^-beta work). 

The gradient is a bit annoying to deal with because you need to use eq 12 in megan's paper in order to reduce something...? Either way in order to do the computation.

The goal in this new code is to, instead of using a loss function of the cumulative work, to use a loss function that finds optimal chebyshev polynomial coefficients using some form of gradient descent.

Ok there is a set of parameters I need in order to

#Imports & Utils
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# token='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'
# !pip install git+https://$token@github.com/mc2engel/noneq_opt.git --upgrade
# 
# !pip install -U tensorflow-probability[jax]
# !pip install -q git+https://www.github.com/google/jax-md
# 
# #!pip install --upgrade tb-nightly==2.5.0a20201203 tbp-nightly==2.4.0a20201203 tf-nightly==2.5.0.dev20201203 tensorboard-plugin-wit==1.7.0

#from google.colab import drive
#drive.mount('/content/drive')

#import jax.tools.colab_tpu
#jax.tools.colab_tpu.setup_tpu()

import time 
import collections
import functools
import os
import pickle 

import jax
import jax.numpy as jnp

from jax.scipy import ndimage
from scipy import integrate

from jax import jit
from jax import grad
from jax import vmap
from jax import value_and_grad

from jax import random
from jax import lax
from jax import ops

from jax.experimental import stax
from jax.experimental import optimizers as jopt

from jax_md import space
from jax_md import minimize
from jax_md import simulate
from jax_md import space
from jax_md import energy
from jax_md import quantity
from jax_md import smap
import jax_md as jmd

f32 = jnp.float32
f64 = jnp.float64

import matplotlib.pyplot as plt
from matplotlib import animation
from matplotlib.animation import ArtistAnimation
from matplotlib import rc
from matplotlib import colors
import seaborn as sns
rc('animation', html='jshtml')
from mpl_toolkits.axes_grid1.inset_locator import inset_axes

import tqdm
import time
import typing

import sys

import scipy as sp
import scipy.special as sps

from numpy import polynomial
import numpy as onp 

import jax.profiler
server = jax.profiler.start_server(port=1234)

from tensorflow_probability.substrates import jax as tfp
tfd = tfp.distributions

"""#Function definitions

##Miscellaneous
"""

# SAVE FILE PATH
save_filepath = "./bc_epsilon_"+sys.argv[1]+"/"

def seed_stream(seed): #will 'yield' a diff. random # each time it is called
  k = jax.random.PRNGKey(seed)
  while True:
    k, y = jax.random.split(k)
    yield y

def plot_with_stddev(x, label=None, n=1, axis=0, ax=plt):
  stddev = jnp.std(x, axis)
  mn = jnp.mean(x, axis)

  ax.fill_between(jnp.arange(mn.shape[0]),
                  mn + n * stddev, mn - n * stddev, alpha=.3)
  ax.plot(mn, '-o', label=label)

"""##Custom Brownian simulator

This is a modification of the JAX-MD Brownian simulator that also returns the log probability of any trajectory that runs. This is needed in order to compute gradients correctly (eq'n 12 in my arXiv paper)
"""

class BrownianState(collections.namedtuple('BrownianState',
                                           'position mass rng log_prob')):
  pass

def brownian(energy_or_force,
             shift,
             dt,
             T_schedule,
             gamma=0.1):
  """Simulation of Brownian dynamics.
  This code simulates Brownian dynamics which are synonymous with the overdamped
  regime of Langevin dynamics. However, in this case we don't need to take into
  account velocity information and the dynamics simplify. Consequently, when
  Brownian dynamics can be used they will be faster than Langevin. As in the
  case of Langevin dynamics our implementation follows [1].
  Args:
    energy_or_force: A function that produces either an energy or a force from
      a set of particle positions specified as an ndarray of shape
      [n, spatial_dimension].
    shift_fn: A function that displaces positions, R, by an amount dR. Both R
      and dR should be ndarrays of shape [n, spatial_dimension].
    dt: Floating point number specifying the timescale (step size) of the
      simulation.
    T_schedule: Either a floating point number specifying a constant temperature
      or a function specifying temperature as a function of time.
    quant: Either a quantity.Energy or a quantity.Force specifying whether
      energy_or_force is an energy or force respectively.
    gamma: A float specifying the friction coefficient between the particles
      and the solvent.
  Returns:
    See above.
    [1] E. Carlon, M. Laleman, S. Nomidis. "Molecular Dynamics Simulation."
        http://itf.fys.kuleuven.be/~enrico/Teaching/molecular_dynamics_2015.pdf
        Accessed on 06/05/2019.
  """

  force_fn = jmd.quantity.canonicalize_force(energy_or_force)

  dt, gamma = jmd.util.static_cast(dt, gamma)

  T_schedule = jmd.interpolate.canonicalize(T_schedule)

  def _dist(state, t, **kwargs):
    nu = jnp.float32(1) / (state.mass * gamma)
    F = force_fn(state.position, t=t, **kwargs)
    mean =  F * nu * dt
    variance = jnp.float32(2) * T_schedule(t) * dt * nu
    return tfd.Normal(mean, jnp.sqrt(variance))
  
  def init_fn(key, R, mass=jnp.float32(1)):
    mass = jmd.quantity.canonicalize_mass(mass)
    return BrownianState(R, mass, key, 0.)

  def apply_fn(state, t=jnp.float32(0), **kwargs):
    dist = _dist(state, t, **kwargs)
    key, split = jax.random.split(state.rng)

    # We have to stop gradients here, otherwise the gradient with respect to
    # energy/force is zero. The following is a simple repro of the issue:
    #  def sample_log_prob(mean, key):
    #    d = tfd.Normal(mean, 1.)
    #    s = d.sample(seed=key)
    #    return d.log_prob(s)
    #  jax.grad(sample_log_prob)(0., key)  # Always 0 !
    dR = jax.lax.stop_gradient(dist.sample(seed=split))

    log_prob = dist.log_prob(dR).sum()
    R = shift(state.position, dR, t=t, **kwargs)
    return BrownianState(R, state.mass, key, log_prob)

  return init_fn, apply_fn

"""##Protocol parametrizations"""

def chebyshev_coefficients(degree):
  return onp.stack([onp.concatenate(
        [onp.zeros(degree - j), sps.chebyt(j, True)])
    for j in range(degree + 1)])
  
def chebyshev_coefficients_nonmonic(degree):
  return onp.stack([onp.concatenate(
        [onp.zeros(degree - j), sps.chebyt(j, False)])
    for j in range(degree + 1)])
  
class Chebyshev(typing.NamedTuple):
  weights: jnp.array

  @property
  def degree(self):
    return self.weights.shape[0] - 1

  @property
  def coefficients(self):
    return chebyshev_coefficients(self.degree)

  def _powers(self, x):
    def _multiply_by_x(y, _):
      y *= x
      return y, y
    ones = jnp.ones_like(x)
    _, powers = jax.lax.scan(
        _multiply_by_x, ones, None, length=self.degree, reverse=True)
    return jnp.concatenate([powers, ones[jnp.newaxis]], axis=0)

  def __call__(self, x):
    """`x` is an array of values in (0, 1)."""
    x = 2. * x - 1.  # Rescale (0, 1) -> (-1, 1)
    x_powers = self._powers(x)
    return jnp.einsum(
        'w,wp,px->x', self.weights, self.coefficients, x_powers)

def MakeSchedule_chebyshev(timevec,coeffs,r0_init,r0_final):
  timevec = timevec[1:-1]
  scaled_timevec = timevec/timevec[-1]
  vals = Chebyshev(coeffs)(scaled_timevec)
  vals = jnp.concatenate([vals, jnp.reshape(r0_final, [1])])
  vals = jnp.concatenate([jnp.reshape(r0_init, [1]), vals])
  return vals
  
# def MakeSchedule_linear(schedule,sim_steps,r0_init,r0_final): #ideally, len(sched)+2 should divide into the final simulated time
#       sim_steps=jnp.arange(1,simulation_steps-1)
#       N=len(schedule)-1
#       span=(sim_steps[-1]-sim_steps[0])
#       inds = jnp.array([(N/span)*(sim_steps-1)])

# #     enforce r0[0] = init, r0[tf] = final
#       mapped_sched=ndimage.map_coordinates(schedule,inds,1)#linear interpolation
#       mapped_sched = jnp.concatenate([mapped_sched, jnp.reshape(r0_final, [1])])
#       mapped_sched = jnp.concatenate([jnp.reshape(r0_init, [1]), mapped_sched])
#       return mapped_sched

"""##Potential energy functions"""

def V_biomolecule(kappa_l, kappa_r, x_m, delta_E, k_s, beta, epsilon, sigma):
  def total_energy(position, r0=0.0, **unused_kwargs):
      x = position[0][0]
      #underlying energy landscape:
      # 1/beta * log(e^(-0.5 beta kappa_1 (x + x_m)^2) + )
      Em = epsilon * ((1 - (x/sigma - 1)**2)**2 + (epsilon/2)*((x/sigma) - 1))
      #moving harmonic potential:
      Es = k_s/2 * (x-r0) ** 2
      return Em + Es
  return total_energy

def V_simple_spring(r0,k,box_size):
  def spring_energy(position, **unused_kwargs):
    #dR = jnp.mod((position - r0) + box_size * f32(0.5), box_size) - f32(0.5) * box_size
    dR=(position[0][0]-r0)
    return k/2 * dR ** 2
  return spring_energy

"""##Functions for estimating gradients of the MD simulations"""

def run_brownian_opt(energy_fn, coeffs, init_position, r0_init, r0_final, Neq, shift, key, simulation_steps, dt=1e-5, temperature=1e-5, mass=1.0, gamma=1.0):
  """Simulation of Brownian particle being dragged by a moving harmonic trap.
  Args:
    energy_fn: the function that governs particle energy. Here, an external harmonic potential
    r0_init: initial position of the trap, for which equilibration is done
    Neq: number of equilibration steps
    shift: shift_fn governing the Brownian simulation
    key: random key
    num_steps: total # simulation steps
    dt: integration time step 
    temperature: simulation temperature kT

  Returns:
    total work required to drag the particle, from eq'n 17 in Jarzynski 2008
  """
  sim_step = jnp.arange(simulation_steps)  
  trap_fn = make_trap_fxn(sim_step,coeffs,r0_init,r0_final)

  def equilibrate(init_state, Neq, apply, r0_init):
    @jit
    def scan_eq(state, step):
      state = apply(state, step, r0=r0_init)
      return state, 0
    state, _ = lax.scan(scan_eq,init_state,jnp.arange(Neq))
    return state
    
  def increment_work(state, step):
        return (energy_fn(state.position, r0=trap_fn(step)) - energy_fn(state.position, r0=trap_fn(step-1)))

  @jit
  def scan_fn(state, step):
    dW = increment_work(state, step) #increment based on position BEFORE 'thermal kick' a la Crooks
    # Dynamically pass r0 to apply, which passes it on to energy_fn
    state = apply(state, step, r0=trap_fn(step))
    return state, (state.position, state.log_prob, dW)

  key, split = random.split(key)  

  init, apply = brownian(energy_fn, shift, dt=dt, T_schedule=temperature, gamma=gamma)
  apply = jit(apply)

  eq_state = equilibrate(init(split, init_position, mass=mass), Neq, apply, r0_init)
  state = eq_state
  state, (positions, log_probs, works) = lax.scan(scan_fn,state,(jnp.arange(simulation_steps-1)+1))
  #print("Log probability:")
  #print(log_probs)
  works = jnp.concatenate([jnp.reshape(0., [1]), works])
  positions = jnp.concatenate([jnp.reshape(eq_state.position, [1,1,1]), positions])
  return positions, log_probs, works

def single_estimate(energy_fn, init_position, r0_init, r0_final, Neq, shift, simulation_steps, dt, temperature, mass, gamma):
  @functools.partial(jax.value_and_grad, has_aux=True) #the 'aux' is the summary
  def _single_estimate(coeffs, seed): #function only of the params to be differentiated w.r.t.
      # OLD forward direction
      positions, log_probs, works = run_brownian_opt(
          energy_fn, coeffs,
          init_position, r0_init, r0_final,
          Neq, shift, seed, simulation_steps, 
          dt, temperature, mass, gamma
          )
      total_work = works.sum()
      tot_log_prob = log_probs.sum()
      summary = (positions, tot_log_prob, total_work)
      
      gradient_estimator = (tot_log_prob * jax.lax.stop_gradient(total_work) + total_work) 
      
      return gradient_estimator, summary
  return _single_estimate 

def estimate_gradient(batch_size, energy_fn, init_position, r0_init, r0_final, Neq, shift, simulation_steps, dt, temperature, mass, gamma):
    mapped_estimate = jax.vmap(single_estimate(energy_fn, init_position, r0_init, r0_final, Neq, shift, simulation_steps, dt, temperature, mass, gamma), [None, 0])
    #mapped_estimate = jax.soft_pmap(lambda s: single_estimate(energy_fn, init_position, r0_init, r0_final, Neq, shift, simulation_steps, dt, temperature, mass, gamma), [None, 0])
    @jax.jit #why am I allowed to jit something whose output is a function? Thought it had to be pytree output...
    def _estimate_gradient(coeffs, seed):
      seeds = jax.random.split(seed, batch_size)
      (gradient_estimator, summary), grad = mapped_estimate(coeffs, seeds)
      return jnp.mean(grad, axis=0), (gradient_estimator, summary)
    return _estimate_gradient # < # delta ln P (W not graded) + delta W > averaged over,

"""## Making Trap Trajectory (Forward & Reverse)"""

def make_trap_fxn(timevec,coeffs,r0_init,r0_final):
  positions = MakeSchedule_chebyshev(timevec,coeffs,r0_init,r0_final)
  def Get_r0(step):
    return positions[step]
  return Get_r0

def make_trap_fxn_rev(timevec,coeffs,r0_init,r0_final):
  """ Returns function with slices/index inputs that returns
    the reverse time trap position depending on the chebyshev """
  positions = jnp.flip(MakeSchedule_chebyshev(timevec,coeffs,r0_init,r0_final))
  def Get_r0(step):
    return positions[step]
  return Get_r0

# == Finding the Chebyshev coefficients for a line y = mx + y_intercept,
# where m = (r0_final - r0_init)/sim_steps
def lin_cheby_coef(r0_init, r0_final, simulation_steps, degree=12, y_intercept = 0):
  slope = (r0_final - r0_init)/simulation_steps
  vals = slope*jnp.arange(0,simulation_steps+1) + y_intercept
  xscaled=jnp.arange(simulation_steps+1)/simulation_steps

  p = onp.polynomial.Chebyshev.fit(xscaled, vals, degree, domain=[0,1])

  return p.coef # This is the coefficients that we are looking for

"""#Simulations

##Brownian particle simulation

###Parameters:
"""

#the parameters as I have set them are meant to be similar to an experiment where DNA hairpins are unfolded by laser tweezers

N = 1 # number of particles
dim = 1 # number of dimensions
end_time = 0.01 
dt = 3e-7 #integration time step
simulation_steps = int((end_time)/dt)+1
teq=0.001 #how long to let the system equilibrate in the initial potentials before you start applying the protocol 
Neq=int(teq/dt) #number of equilibration timesteps

batch_size=5000 # how many simulations/trajectories to perform
beta=1.0/4.114 #inverse temperature kT (Boltzmann factor times temperature)
mass = 1e-17 #particle mass 
D = 0.44*1e6 #diffusion constant (tells you how fast the particle is able to move around (friction slows it down)) 
gamma = 1./(beta*D*mass) #friction coefficient

k_s = 0.4 #stiffness
epsilon = int(sys.argv[1])/2 * (1.0/beta) # PRESIDENTIAL EPSILON
print(f"Epsilon is: {int(sys.argv[1])/2} * 1/beta = {epsilon}")
sigma = 1.0/jnp.sqrt(beta * k_s)

#harmonic potential (I call it a "trap") parameters:
r0_init = -0. #initial pos
r0_final = sigma*2. #final pos

#landscape params (see the 2016 Sivak and Crooks paper for what the parameters mean in the mathematical expression)
x_m=10. #How far the energy barrier is from the left-most well 
delta_E=0 #how separated the two minima are from each other -- take them to be at the same height
kappa_l=6.38629/(beta*x_m**2)#for a barrier height 2.5kT
kappa_r=kappa_l #set wells to have equal curvature (not necessary for us, but 2016 Crooks paper does this)

"""###Run Simulation:"""
trap_coeffs = lin_cheby_coef(r0_init, r0_final, simulation_steps, degree = 12, y_intercept = 0.) # what shape the trap protocol is 
trap_fn = make_trap_fxn(jnp.arange(simulation_steps), trap_coeffs, r0_init, r0_final)


def simulate_protocol(trap_coeffs):  
  #generate random keys for simulation:

  key = random.PRNGKey(int(time.time()))
  key, split = random.split(key, 2)
  init_position=-0.*jnp.ones((N,dim)) #initial particle location

  #see JAX-MD documentation for details on how these energy/force/displacement functions work:
  energy_fn = V_biomolecule(kappa_l, kappa_r, x_m, delta_E, k_s, beta, epsilon, sigma)
  force_fn = quantity.force(energy_fn)
  displacement_fn, shift_fn = space.free()

  tot_works = []

  # To generate a bunch of samples, we 'map' across seeds.
  mapped_sim = jax.soft_pmap(lambda keys : run_brownian_opt(energy_fn, trap_coeffs, init_position, r0_init, r0_final, Neq, shift_fn, keys, simulation_steps, dt, 1./beta, mass, gamma))
  seeds = jax.random.split(split, batch_size)
  trajectories, _, works = mapped_sim(seeds) #seed is array with diff seed for each run. I'm discarding the log prob data, here

  tot_works = jnp.sum(works, 1)
  
  return tot_works, (trajectories, works)


tot_works, (trajectories, works) = simulate_protocol(trap_coeffs)
print("average work done in moving the particle: ",jnp.mean(tot_works))

"""###plots"""

#what the underlying 'molecular' potential looks like:

x=jnp.linspace(-4,10,200)
xvec=jnp.reshape(jnp.linspace(-4,10,200), [200,1,1])
k_splot = 0.
Vfn = V_biomolecule(0, 0, 0, 0, k_splot, beta, epsilon, sigma) # returns in pN nm
V = []
for j in range(len(xvec)):
  V.append(Vfn(xvec[j], r0=0.))
plt.figure(figsize=(10,10))
plt.plot(x,V,'-o')
plt.savefig(save_filepath+ "potential.png")
plt.show()
####PLOT RESULTS FORWARD#####

_, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=[30, 12])
ax0.plot(dt*1000*jnp.arange(simulation_steps),trap_fn(jnp.arange(simulation_steps)), '-o')
ax0.set(xlabel="time (ms)")
ax0.set_title('Initial trap schedule')



for j in range(batch_size):
    if j % 1000 == 0:
      ax1.plot(dt*1000*jnp.arange(simulation_steps), trajectories[j][:,0,0])
#ax1.legend()#
ax1.set(xlabel="time (ms)")
ax1.set_title('Particle positions')


for j in range(batch_size):
  if j % 1000 == 0:
    ax2.plot(dt*1000*jnp.arange(simulation_steps)+1, works[j], '-o')
#ax2.plot(dt*1000*jnp.arange(simulation_steps)+1, summary[1], '-o')
ax2.set(xlabel="time (ms)")
ax2.set_title('Energy increments')
plt.savefig(save_filepath+ "forward_sim.png")
plt.show()

####PLOT RESULTS BACKWARD#####
back_sim_steps = jnp.flip(jnp.arange(simulation_steps))
_, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=[30, 12])
ax0.plot(dt*1000*back_sim_steps,trap_fn(jnp.flip(back_sim_steps)), '-o')
ax0.set(xlabel="time (ms)")
ax0.set_title('Initial backwards trap schedule')



for j in range(batch_size):
    if j % 1000 == 0:
      ax1.plot(dt*1000*back_sim_steps, trajectories[j][:,0,0])
#ax1.legend()#
ax1.set(xlabel="time (ms)")
ax1.set_title('Backward Particle positions')


for j in range(batch_size):
  if j % 1000 == 0:
    ax2.plot(dt*1000*back_sim_steps+1, works[j], '-o')
#ax2.plot(dt*1000*jnp.arange(simulation_steps)+1, summary[1], '-o')
ax2.set(xlabel="time (ms)")
ax2.set_title('Backward Energy increments')
plt.savefig(save_filepath+ "backward_sim.png")
plt.show()

##### PLOT WORK DISTRIBUTION #####
plt.figure(figsize=[12, 12])
# plt.hist(jnp.array(tot_works)*beta,20,alpha=1.0,color='g')

plt.xlabel("Work (kbT)")
plt.ylabel("counts")
plt.legend()
plt.savefig(save_filepath+ "USELESSwork_distribution.png")
plt.show()
print("forward mean:", jnp.mean(jnp.array(tot_works)*beta), "kbT")

"""## Optimization of trap protocol

### Parameters
"""

# Delete files in case crowded directory.
#for f in os.listdir(save_filepath):
#    os.remove(os.path.join(save_filepath, f))

# Hyper parameters
N = 1
dim = 1
end_time = 0.01 #s
dt = 3e-7 #s
simulation_steps = int((end_time)/dt)+1
teq=0.001 #s
Neq=int(teq/dt)

batch_size= 3600#2504 number of trajectories
opt_steps = 500#1000 number of optimization steps
#temperature = 4.114 #at 298K = 25C
temperature = 4.183 #at 303K=30C
beta=1.0/temperature #1/(pNnm)
mass = 1e-17 #1e-17 #g
D = 0.44*1e6 #(in nm**2/s) 
gamma = 1./(beta*D*mass) #s^(-1)
init_position=-0.*jnp.ones((N,dim)) #nm

k_s = 0.4 #stiffness
# epsilon = 0.5 * (1.0/beta)
sigma = 1.0/jnp.sqrt(beta * k_s)

#harmonic potential (I call it a "trap") parameters:
r0_init = -0. #initial pos
r0_final = sigma*2. #final pos

#landscape params:
x_m=10. #nm
delta_E=0 #pN nm
kappa_l=21.3863/(beta*x_m**2) #pN/nm #for Ebarrier = 10kT and delta_E=0, as C&S use
#kappa_l=6.38629/(beta*x_m**2) #pN/nm #for Ebarrier = 2.5kT and delta_E=0, as C&S use
#kappa_l=2.6258/(beta*x_m**2)#barrier 0.625kT
kappa_r=kappa_l #pN/nm 

energy_fn = V_biomolecule(kappa_l, kappa_r, x_m, delta_E, k_s, beta, epsilon, sigma)
force_fn = quantity.force(energy_fn)
displacement_fn, shift_fn = space.free()

"""###Optimization

Note, I think the gradient isn't actually taking the average, but rather just taking a sum over all trajectories... maybe?

Nah probably not.
"""

init_coeffs = lin_cheby_coef(r0_init, r0_final, simulation_steps, degree =12, y_intercept = 0.) # This implements a linear schedule
trap_fn = make_trap_fxn(jnp.arange(simulation_steps), init_coeffs, r0_init, r0_final)

#optimizer = jopt.adam(.1)
#use learning rate decay to converge more accurately on the global opt value:
lr = jopt.exponential_decay(0.1, opt_steps, 0.001)
optimizer = jopt.adam(lr)

total_norm = 0 
summaries = []
coeffs_ = []
all_works = []
init_state = optimizer.init_fn(init_coeffs)
opt_state = optimizer.init_fn(init_coeffs)
key = random.PRNGKey(int(time.time()))
key, split = random.split(key, 2)

grad_fxn = estimate_gradient(batch_size, energy_fn, init_position, r0_init, r0_final, Neq, shift_fn, simulation_steps, dt, temperature, mass, gamma)
coeffs_.append((0,) + (optimizer.params_fn(opt_state),))

for j in tqdm.trange(opt_steps,position=0):
  key, split = random.split(key)
  grad, (_, summary) = grad_fxn(optimizer.params_fn(opt_state), split)
  print(grad)
  print(f"\n Gradient norm: {jnp.linalg.norm(grad)}")
  total_norm += jnp.linalg.norm(grad)
  opt_state = optimizer.update_fn(j, grad, opt_state)
  all_works.append(summary[2])
  if j % 100 == 0:
    coeffs_.append(((j+1),) + (optimizer.params_fn(opt_state),))
  if j == (opt_steps-1):
    coeffs_.append((j+1,) + (optimizer.params_fn(opt_state),))
    
coeffs_.append((opt_steps,) + (optimizer.params_fn(opt_state),))


print("init parameters: ", optimizer.params_fn(init_state))
print("final parameters: ", optimizer.params_fn(opt_state))
#all_summaries = jax.tree_multimap(lambda *args: jnp.stack(args), *summaries)
all_works = jax.tree_multimap(lambda *args: jnp.stack(args), *all_works)

# note that you cannot pickle locally-defined functions 
# (like the log_temp_baseline() thing), so I need to save the weights 
# and then later recreate the schedules
afile = open(save_filepath+'coeffs.pkl', 'wb')
pickle.dump(coeffs_, afile)
afile.close()

bfile = open(save_filepath+'works.pkl', 'wb')
pickle.dump(all_works, bfile)
bfile.close()

print(f"Final norm: {total_norm/opt_steps}")
"""
file = open("./FORWARD_COEFFS.pkl", 'rb')
coeffs_ = pickle.load(file)
file.close()

file = open("./FORWARD_WORKS.pkl",'rb')
all_works = pickle.load(file)
file.close()"""

"""###Plots"""

#plot work distns 
plt.figure(figsize=[12, 12])
for j in range(opt_steps):
  if(j%100 == 0):
    work_dist = all_works[j,:]
    plt.hist(work_dist,10,label=f'Step {j}')

plt.legend()#

##### PLOT LOSS AND SCHEDULE EVOLUTION #####
_, (ax0, ax1) = plt.subplots(1, 2, figsize=[24, 12])
plot_with_stddev(all_works.T, ax=ax0)
#ax0.set_ylim([0.1,1.0])
#ax0.set_xlim([0,200])
ax0.set_title('Total work')

trap_fn = make_trap_fxn(jnp.arange(simulation_steps), init_coeffs, r0_init, r0_final)
init_sched = trap_fn(jnp.arange(simulation_steps))
ax1.plot(jnp.arange(simulation_steps), init_sched, label='initial guess')

for j, coeffs in coeffs_:
  #if(j%50 == 0):
  trap_fn = make_trap_fxn(jnp.arange(simulation_steps),coeffs,r0_init,r0_final)
  full_sched = trap_fn(jnp.arange(simulation_steps))
  ax1.plot(jnp.arange(simulation_steps), full_sched, '-', label=f'Step {j}')

#plot final estimate:
trap_fn = make_trap_fxn(jnp.arange(simulation_steps),coeffs_[-1][1],r0_init,r0_final)
full_sched = trap_fn(jnp.arange(simulation_steps))
ax1.plot(jnp.arange(simulation_steps), full_sched, '-', label=f'Final')



ax1.legend()#
ax1.set_title('Schedule evolution')
plt.savefig(save_filepath+ "forward_optimization.png")
plt.show()

"""# Calculating Jarzynski Equality Error"""

def rev_single_estimate(energy_fn, init_position, r0_init, r0_final, Neq, shift, simulation_steps, dt, temperature, mass, gamma, beta):
  @functools.partial(jax.value_and_grad, has_aux = True)
  def _single_estimate(coeffs, seed):
      positions, log_probs, works = run_brownian_opt(
          energy_fn, coeffs,
          init_position, r0_init, r0_final,
          Neq, shift, seed, simulation_steps, 
          dt, temperature, mass, gamma
          )
      total_work = works.sum()
      tot_log_prob = log_probs.sum()
      summary = (positions, tot_log_prob, jnp.exp(beta*total_work))

      # NEW delta ln P * e^(beta W) (not graded) + delta W * e^(beta W) (no grad)
      gradient_estimator = (tot_log_prob) * jax.lax.stop_gradient(jnp.exp(beta * total_work)) + jax.lax.stop_gradient(beta * jnp.exp(beta*total_work)) * total_work
      return gradient_estimator, summary
  return _single_estimate 

def estimate_gradient_rev(batch_size, energy_fn, init_position, r0_init, r0_final, Neq, shift, simulation_steps, dt, temperature, mass, gamma, beta):
    mapped_estimate = jax.vmap(rev_single_estimate(energy_fn, init_position, r0_init, r0_final, Neq, shift, simulation_steps, dt, temperature, mass, gamma, beta), [None, 0])  
    @jax.jit 
    def _estimate_gradient(coeffs, seed):
      seeds = jax.random.split(seed, batch_size)
      (gradient_estimator, summary), grad = mapped_estimate(coeffs, seeds)
      return jnp.mean(grad, axis=0), (gradient_estimator, summary)
    return _estimate_gradient # < # delta ln P (W not graded) + delta W > averaged over,

# ============== PARAMETERS ================

# Hyper parameters
N = 1
dim = 1
end_time = 0.01 #s
dt = 3e-7 #s
simulation_steps = int((end_time)/dt)+1
teq=0.001 #s
Neq=int(teq/dt)

batch_size= 3600#2504 number of trajectories
opt_steps = 500#1000 number of optimization steps
#temperature = 4.114 #at 298K = 25C
temperature = 4.183 #at 303K=30C
beta=1.0/temperature #1/(pNnm)
mass = 1e-17 #1e-17 #g
D = 0.44*1e6 #(in nm**2/s) 
gamma = 1./(beta*D*mass) #s^(-1)

k_s = 0.4 #pN/nm
# epsilon = 0.5 * (1.0/beta)
sigma = 1.0/jnp.sqrt(beta * k_s)

#harmonic potential (I call it a "trap") parameters:
r0_init = -0. #initial pos
r0_final = sigma*2. #final pos


#landscape params:
x_m=10. #nm
delta_E=0 #pN nm
kappa_l=21.3863/(beta*x_m**2) #pN/nm #for Ebarrier = 10kT and delta_E=0, as C&S use
#kappa_l=6.38629/(beta*x_m**2) #pN/nm #for Ebarrier = 2.5kT and delta_E=0, as C&S use
#kappa_l=2.6258/(beta*x_m**2)#barrier 0.625kT
kappa_r=kappa_l #pN/nm 

energy_fn = V_biomolecule(kappa_l, kappa_r, x_m, delta_E, k_s, beta, epsilon, sigma)
force_fn = quantity.force(energy_fn)
displacement_fn, shift_fn = space.free()

# ======== REVERSE OPTIMIZATION =============

init_coeffs = lin_cheby_coef(r0_init, r0_final, simulation_steps, degree = 12, y_intercept = 0.)

trap_fn = make_trap_fxn_rev(jnp.arange(simulation_steps), init_coeffs, r0_init, r0_final)
key = random.PRNGKey(int(time.time()))
key, split = random.split(key, 2)

# use learning rate decay (ADAMS) to converge more accurately on the global opt value:
lr = jopt.exponential_decay(0.1, opt_steps, 0.001)
optimizer = jopt.adam(lr)

# rev_summaries = []
rev_coeffs_ = []
rev_all_works = []

init_state = optimizer.init_fn(init_coeffs)
opt_state = optimizer.init_fn(init_coeffs)

rev_init_pos = r0_final * jnp.ones((N,dim))
rev_grad_fxn = estimate_gradient_rev(
    batch_size, energy_fn, rev_init_pos, 
    r0_init, r0_final, Neq, shift_fn, 
    simulation_steps, dt, 
    temperature, mass, gamma, beta
    )

rev_coeffs_.append((0,) + (optimizer.params_fn(opt_state),))

for j in tqdm.trange(opt_steps,position=0):
  key, split = random.split(key)
  grad, (_, summary) = rev_grad_fxn(optimizer.params_fn(opt_state), split)
  print(grad)
  opt_state = optimizer.update_fn(j, grad, opt_state)
  rev_all_works.append(summary[2])
  
  if j % 100 == 0:
    rev_coeffs_.append(((j+1),) + (optimizer.params_fn(opt_state),))
  if j == (opt_steps-1):
    rev_coeffs_.append((j+1,) + (optimizer.params_fn(opt_state),))
    
rev_coeffs_.append((opt_steps,) + (optimizer.params_fn(opt_state),))

rev_power_works = jnp.exp(jnp.array(rev_all_works))

print("init parameters: ", optimizer.params_fn(init_state))
print("final parameters: ", optimizer.params_fn(opt_state))
#all_summaries = jax.tree_multimap(lambda *args: jnp.stack(args), *summaries)
rev_power_works = jax.tree_multimap(lambda *args: jnp.stack(args), *rev_power_works)
# note that you cannot pickle locally-defined functions 
# (like the log_temp_baseline() thing), so I need to save the weights 
# and then later recreate the schedules
afile = open(save_filepath+'rev_coeffs.pkl', 'wb')
pickle.dump(rev_coeffs_, afile)
afile.close()

bfile = open(save_filepath+'rev_works.pkl', 'wb')
pickle.dump(rev_all_works, bfile)
bfile.close()

##### PLOT REVERSE WORKS #####
_, (ax0, ax1) = plt.subplots(1, 2, figsize=[24, 12])
plot_with_stddev(rev_power_works.T, ax=ax0)


ax0.set_title('Error (Exponential)')

trap_fn = make_trap_fxn_rev(jnp.arange(simulation_steps), init_coeffs, r0_init, r0_final)
init_sched = trap_fn(jnp.arange(simulation_steps))
ax1.plot(jnp.arange(simulation_steps) * dt, init_sched, label='initial guess')

for j, coeffs in rev_coeffs_:
  #if(j%50 == 0):
  trap_fn = make_trap_fxn_rev(jnp.arange(simulation_steps),coeffs,r0_init,r0_final)
  full_sched = trap_fn(jnp.arange(simulation_steps))
  ax1.plot(jnp.arange(simulation_steps) * dt, full_sched, '-', label=f'Step {j}')

#plot final estimate:
trap_fn = make_trap_fxn_rev(jnp.arange(simulation_steps),rev_coeffs_[-1][1],r0_init,r0_final)
full_sched = trap_fn(jnp.arange(simulation_steps))
ax1.plot(jnp.arange(simulation_steps) * dt, full_sched, '-', label=f'Final')



ax1.legend()#
ax1.set_title('Schedule evolution')
plt.savefig(save_filepath+ "backward_optimization.png")
plt.show()

"""# Finding Average Work for Optimized Coefficients"""



"""# Final Plots"""

fig, ax = plt.subplots(figsize=(12,12))

ax.set_title('Optimal Protocols for Work vs. Error')

error_trap_fn = make_trap_fxn(jnp.arange(simulation_steps),rev_coeffs_[-1][1],r0_init,r0_final)
error_sched = error_trap_fn(jnp.arange(simulation_steps))
ax.plot(jnp.arange(simulation_steps), error_sched, '-', label=f'Error Optimized')

work_trap_fn = make_trap_fxn(jnp.arange(simulation_steps),coeffs_[-1][1],r0_init,r0_final)
work_sched = work_trap_fn(jnp.arange(simulation_steps))
ax.plot(jnp.arange(simulation_steps), work_sched, '-', label=f'Work Optimized')

ax.set_xlabel("Time (ns)")
ax.set_ylabel("Position (x)")
ax.legend()#
plt.savefig(save_filepath + "finalprotocols.png")
plt.show()

# Fig. 11 (epsilon = 0.5 k_B T), Geiger et al. 2010

linear_works, _ = simulate_protocol(coeffs_[0][1])
forward_optimized_works, _ = simulate_protocol(coeffs_[-1][1])
backward_optimized_works, _ = simulate_protocol(rev_coeffs_[-1][1])
lin_avg = jnp.mean(linear_works)
forward_avg = jnp.mean(forward_optimized_works)
backward_avg = jnp.mean(backward_optimized_works)

print(f"Linear protocol; work used: {lin_avg}")
print(f"Forward-direction Work-optimized protocol; work used: {forward_avg}")
print(f"Backward-direction Error-optimized protocol; work used: {backward_avg}")
print("Ratios:")
print(f"Forward/Linear: {forward_avg/lin_avg}")
print(f"Backward/Linear: {backward_avg/lin_avg}")

import pandas as pd

df = pd.DataFrame([
                   {"Name": "Linear Average", "Value": lin_avg}, 
                   {"Name": "Forward Average", "Value": forward_avg}, 
                   {"Name": "Backward Average", "Value": backward_avg}, 
                   {"Name": "Forward/Linear Ratio", "Value": forward_avg/lin_avg},
                   {"Name": "Backward/Linear Ratio", "Value": backward_avg/lin_avg}])
df.set_index("Name").to_csv(save_filepath + "work_outputs.csv")



